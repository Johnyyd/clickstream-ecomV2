# üìä Comprehensive Clickstream Analytics Guide

## üéØ M·ª•c ti√™u

H·ªá th·ªëng ph√¢n t√≠ch clickstream to√†n di·ªán ƒë·ªÉ:
- ‚úÖ T·ªëi ∆∞u tr·∫£i nghi·ªám kh√°ch h√†ng (UX)
- ‚úÖ ƒê∆∞a ra ƒë·ªÅ xu·∫•t s·∫£n ph·∫©m c√° nh√¢n h√≥a
- ‚úÖ X√¢y d·ª±ng chi·∫øn d·ªãch marketing hi·ªáu qu·∫£
- ‚úÖ Ph√¢n t√≠ch Customer Journey
- ‚úÖ Gi·∫£m bounce rate, tƒÉng conversion rate
- ‚úÖ Cung c·∫•p insights cho SEO/Marketing/Product

---

## üóÇÔ∏è D·ªØ li·ªáu & Collections

| Collection | √ù nghƒ©a | Li√™n k·∫øt |
|------------|---------|----------|
| **users** | Th√¥ng tin ng∆∞·ªùi d√πng, g·ª£i √Ω s·∫£n ph·∫©m | `_id` ‚Üî `events.user_id`, `sessions.user_id` |
| **sessions** | M·ªói l·∫ßn truy c·∫≠p website | `session_id` ‚Üî `events.session_id` |
| **events** | D√≤ng click, h√†nh ƒë·ªông (pageview, add_to_cart, checkout, search) | Li√™n k·∫øt v·ªõi `user_id`, `page`, `timestamp` |
| **products** | S·∫£n ph·∫©m chi ti·∫øt | `product_id` ‚Üî `carts.items.product_id` |
| **carts** | Gi·ªè h√†ng | Li√™n k·∫øt v·ªõi `user_id`, `items.product_id` |

---

## ‚öôÔ∏è Ki·∫øn tr√∫c ph√¢n t√≠ch

### 1Ô∏è‚É£ T·∫ßng Thu th·∫≠p D·ªØ li·ªáu (Data Collection)
- **Event Tracker**: Ghi nh·∫≠n m·ªçi h√†nh ƒë·ªông ng∆∞·ªùi d√πng
- **MongoDB**: L∆∞u tr·ªØ d·ªØ li·ªáu th√¥
- **Kafka** (optional): Stream d·ªØ li·ªáu th·ªùi gian th·ª±c

### 2Ô∏è‚É£ T·∫ßng X·ª≠ l√Ω D·ªØ li·ªáu (Data Processing)
- **Apache Spark**: X·ª≠ l√Ω d·ªØ li·ªáu l·ªõn
- **PySpark SQL**: Truy v·∫•n v√† transform
- **ETL Pipeline**: Extract ‚Üí Transform ‚Üí Load

### 3Ô∏è‚É£ T·∫ßng H·ªçc m√°y & Ph√¢n t√≠ch (ML & Analytics)
- **K-Means**: User Segmentation
- **Decision Tree**: Conversion Prediction
- **Logistic Regression**: Purchase Probability
- **ALS**: Product Recommendations
- **FP-Growth**: Pattern Mining

### 4Ô∏è‚É£ T·∫ßng Hi·ªÉn th·ªã (Visualization)
- **Dashboard**: Power BI, Tableau, ho·∫∑c web-based
- **REST API**: FastAPI endpoints
- **Real-time Updates**: WebSocket (optional)

---

## üìä C√°c Module Ph√¢n t√≠ch

### 1. **SEO & Traffic Source Analysis** 
üìÅ `spark_seo_analytics.py`

**Ch·ª©c nƒÉng:**
- Ph√¢n t√≠ch ngu·ªìn traffic (organic, social, direct, paid)
- Landing page effectiveness
- Bounce rate by source
- Conversion rate by source
- Peak traffic hours

**Usage:**
```python
from spark_seo_analytics import analyze_traffic_sources

result = analyze_traffic_sources(username="alice")
print(result)
```

**Output:**
```json
{
  "algorithm": "SEO & Traffic Source Analysis",
  "traffic_by_source": [
    {"source": "organic_search", "sessions": 150, "events": 1200, "unique_users": 120},
    {"source": "social", "sessions": 80, "events": 600, "unique_users": 70}
  ],
  "landing_pages": [
    {"page": "/home", "sessions": 200, "avg_events": 6.5, "conversion_rate": 0.15, "bounce_rate": 0.25}
  ],
  "conversion_by_source": [...],
  "hourly_traffic": [...]
}
```

---

### 2. **Cart Abandonment Analysis**
üìÅ `spark_cart_analytics.py`

**Ch·ª©c nƒÉng:**
- Cart abandonment rate
- S·∫£n ph·∫©m b·ªã abandon nhi·ªÅu nh·∫•t
- Gi√° tr·ªã gi·ªè h√†ng trung b√¨nh khi abandon
- So s√°nh gi·ªè completed vs abandoned

**Usage:**
```python
from spark_cart_analytics import analyze_cart_abandonment

result = analyze_cart_abandonment(username="bob")
```

**Output:**
```json
{
  "algorithm": "Cart Abandonment Analysis",
  "total_carts": 100,
  "abandoned_carts": 65,
  "abandonment_rate": 65.0,
  "avg_abandoned_value": 125.50,
  "most_abandoned_products": [
    {"product_name": "MacBook Air M3", "abandoned_count": 15}
  ]
}
```

---

### 3. **Cohort & Retention Analysis**
üìÅ `spark_retention_analytics.py`

**Ch·ª©c nƒÉng:**
- Ph√¢n nh√≥m ng∆∞·ªùi d√πng theo ng√†y ƒëƒÉng k√Ω
- Retention rate (Week 1, Week 2, Month 1)
- User segments (Active, At Risk, Churned)
- Churn prediction

**Usage:**
```python
from spark_retention_analytics import analyze_cohort_retention

result = analyze_cohort_retention()
```

**Output:**
```json
{
  "algorithm": "Cohort & Retention Analysis",
  "cohorts": [
    {"cohort_date": "2025-01-15", "cohort_size": 50, "retention_week1": 75.0, "retention_month1": 45.0}
  ],
  "average_retention": {"week1": 70.5, "week2": 55.2, "month1": 42.3},
  "user_segments": [
    {"segment": "Active", "user_count": 500},
    {"segment": "At Risk", "user_count": 200},
    {"segment": "Churned", "user_count": 100}
  ]
}
```

---

### 4. **Customer Journey Path Analysis**
üìÅ `spark_journey_analytics.py`

**Ch·ª©c nƒÉng:**
- Ph√¢n t√≠ch chu·ªói h√†nh ƒë·ªông d·∫´n ƒë·∫øn conversion
- X√°c ƒë·ªãnh drop-off points
- Path length analysis
- Common page sequences

**Usage:**
```python
from spark_journey_analytics import analyze_customer_journey

result = analyze_customer_journey()
```

**Output:**
```json
{
  "algorithm": "Customer Journey Path Analysis",
  "conversion_paths": [
    {"path": "/home -> category -> product -> cart -> checkout", "path_length": 5}
  ],
  "dropoff_points": [
    {"page": "cart", "dropout_count": 150, "avg_events_before": 4.2}
  ],
  "path_statistics": {
    "avg_path_length": 5.8,
    "median_path_length": 5.0
  },
  "common_sequences": [
    {"sequence": "product -> cart", "frequency": 450}
  ]
}
```

---

### 5. **Product Recommendation (ALS)**
üìÅ `spark_recommendation_als.py`

**Ch·ª©c nƒÉng:**
- Collaborative Filtering using ALS
- Personalized product recommendations
- Implicit feedback (pageview=1, add_to_cart=3, purchase=5)
- Top-N recommendations per user

**Usage:**
```python
from spark_recommendation_als import ml_product_recommendations_als

result = ml_product_recommendations_als(username="alice", top_n=5)
```

**Output:**
```json
{
  "algorithm": "ALS Collaborative Filtering",
  "rmse": 0.85,
  "user": "alice",
  "recommendations": [
    {
      "product_name": "iPhone 15 Pro",
      "category": "phone",
      "price": 999.99,
      "predicted_rating": 4.5,
      "reason": "Predicted interest score: 4.5"
    }
  ]
}
```

---

### 6. **User Segmentation (K-Means)**
üìÅ `spark_ml.py`

**Ch·ª©c nƒÉng:**
- Ph√¢n c·ª•m ng∆∞·ªùi d√πng theo h√†nh vi
- Features: total_events, sessions_count, conversion_rate, cart_rate
- 3 clusters: Low/Medium/High value users

**Usage:**
```python
from spark_ml import ml_user_segmentation_kmeans

result = ml_user_segmentation_kmeans()
```

---

### 7. **Conversion Prediction (Decision Tree)**
üìÅ `spark_ml.py`

**Ch·ª©c nƒÉng:**
- D·ª± ƒëo√°n kh·∫£ nƒÉng conversion
- Features: session_duration, page_views, product_views, cart_adds
- Feature importance analysis

**Usage:**
```python
from spark_ml import ml_conversion_prediction_tree

result = ml_conversion_prediction_tree()
```

---

### 8. **Purchase Prediction (Logistic Regression)**
üìÅ `spark_ml.py`

**Ch·ª©c nƒÉng:**
- D·ª± ƒëo√°n x√°c su·∫•t mua h√†ng
- Purchase probability score
- Feature coefficients analysis

**Usage:**
```python
from spark_ml import ml_purchase_prediction_logistic

result = ml_purchase_prediction_logistic()
```

---

### 9. **Pattern Mining (FP-Growth)**
üìÅ `spark_ml.py`

**Ch·ª©c nƒÉng:**
- T√¨m frequent patterns trong page navigation
- Association rules (if X then Y)
- Support v√† confidence metrics

**Usage:**
```python
from spark_ml import ml_pattern_mining_fpgrowth

result = ml_pattern_mining_fpgrowth()
```

---

## üöÄ Quick Start

### 1. Seed d·ªØ li·ªáu th·ª±c t·∫ø
```powershell
python seed_products.py
python seed_realistic_data.py --days 30 --user-count 1000 --sessions-per-user 5 --avg-events 7
```

### 2. Ch·∫°y ph√¢n t√≠ch c∆° b·∫£n
```python
from spark_jobs import sessionize_and_counts

result = sessionize_and_counts(limit=10000)
print(result)
```

### 3. Ch·∫°y t·∫•t c·∫£ c√°c ph√¢n t√≠ch
```python
from spark_seo_analytics import analyze_traffic_sources
from spark_cart_analytics import analyze_cart_abandonment
from spark_retention_analytics import analyze_cohort_retention
from spark_journey_analytics import analyze_customer_journey
from spark_recommendation_als import ml_product_recommendations_als

# SEO Analysis
seo_result = analyze_traffic_sources()

# Cart Analysis
cart_result = analyze_cart_abandonment()

# Retention Analysis
retention_result = analyze_cohort_retention()

# Journey Analysis
journey_result = analyze_customer_journey()

# Recommendations
recs_result = ml_product_recommendations_als(username="alice")
```

---

## üìà Dashboard Metrics

### Traffic Overview
- Total Sessions, Users, Pageviews
- Sessions by Source
- Peak Traffic Hours
- Bounce Rate by Source

### Engagement Metrics
- Avg Session Duration
- Pages per Session
- Multi-page Session Rate
- Return Visitor Rate

### Conversion Funnel
- View ‚Üí Product ‚Üí Cart ‚Üí Checkout ‚Üí Purchase
- Conversion Rate at each step
- Drop-off Analysis

### User Segmentation
- Active Users (last 7 days)
- At Risk Users (8-30 days)
- Churned Users (>30 days)

### Product Insights
- Top Products by Views/Carts/Purchases
- Most Abandoned Products
- Cross-sell Opportunities
- Recommendation Impact

---

## üß© ·ª®ng d·ª•ng K·∫øt qu·∫£

### Marketing
- T·∫°o chi·∫øn d·ªãch remarketing cho abandoned carts
- T·ªëi ∆∞u qu·∫£ng c√°o theo ngu·ªìn traffic hi·ªáu qu·∫£ nh·∫•t
- Personalized email campaigns

### SEO
- T·ªëi ∆∞u landing pages c√≥ bounce rate cao
- C·∫£i thi·ªán meta tags cho trang c√≥ traffic cao
- Internal linking strategy

### UX/UI
- ƒêi·ªÅu ch·ªânh giao di·ªán t·∫°i drop-off points
- A/B testing cho conversion paths
- Mobile optimization

### Product Management
- Hi·ªÉu xu h∆∞·ªõng s·∫£n ph·∫©m ƒëang ƒë∆∞·ª£c quan t√¢m
- Bundle products th∆∞·ªùng xem c√πng nhau
- Pricing optimization

---

## üîó API Endpoints (FastAPI)

```python
# Run all analytics
POST /api/analytics/comprehensive
{
  "username": "alice",  # optional
  "limit": 10000,
  "modules": ["seo", "cart", "retention", "journey", "recommendations"]
}

# Specific analysis
GET /api/analytics/seo?username=alice
GET /api/analytics/cart-abandonment
GET /api/analytics/retention
GET /api/analytics/journey
GET /api/analytics/recommendations/alice
```

---

## üìö Technical Stack

- **Backend**: Python 3.10+, FastAPI
- **Database**: MongoDB
- **Processing**: Apache Spark (PySpark)
- **ML**: Spark MLlib (ALS, K-Means, Decision Tree, Logistic Regression, FP-Growth)
- **Queue**: Apache Kafka (optional)
- **Visualization**: Power BI / Tableau / Custom Dashboard

---

## üí° Best Practices

1. **Data Quality**: Lo·∫°i b·ªè noisy data tr∆∞·ªõc khi ph√¢n t√≠ch
2. **Sampling**: S·ª≠ d·ª•ng limit cho dataset l·ªõn
3. **Caching**: Cache Spark DataFrames cho multiple operations
4. **Incremental Processing**: Ch·ªâ x·ª≠ l√Ω d·ªØ li·ªáu m·ªõi
5. **Monitoring**: Track analysis performance v√† errors
6. **Documentation**: Ghi ch√©p insights v√† decisions

---

## üêõ Troubleshooting

### Spark Out of Memory
```python
# Increase memory
spark = SparkSession.builder \
    .config("spark.driver.memory", "4g") \
    .config("spark.executor.memory", "4g") \
    .getOrCreate()
```

### Slow Performance
- Reduce dataset size with `limit`
- Use `repartition()` for better parallelism
- Cache frequently accessed DataFrames
- Optimize SQL queries

### No Data Found
- Check data filters (flag.noisy, properties.source)
- Verify user exists
- Ensure events have required fields

---

## üìû Support

For issues or questions:
- GitHub Issues
- Documentation: `README.md`, `ANALYSIS_FEATURES.md`
- Code examples: `tests/` directory

---

**Version**: 2.0  
**Last Updated**: 2025-01-21  
**Maintainer**: Clickstream Analytics Team
